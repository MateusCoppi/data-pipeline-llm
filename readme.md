# ğŸ“Š Data Pipeline Project

Projeto de pipeline de dados utilizando **PostgreSQL via Docker**, **Python** e execuÃ§Ã£o de **scripts SQL**, com estrutura organizada para ingestÃ£o, processamento e anÃ¡lises (incluindo uso futuro de LLMs).

---

## ğŸ§° PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Docker**
- **Docker Compose**
- **Python 3.10+**
- **Git** (opcional, mas recomendado)
- **Ollama** (https://ollama.com/library/llama3.1)

---

## ğŸ˜ Banco de Dados (PostgreSQL)

O PostgreSQL Ã© executado via **Docker Compose**.

### Subir o banco
```bash
docker-compose up -d
```

```bash
Estrutura do Projeto
.
â”œâ”€â”€ data_src/        # Fontes de dados (CSV, JSON, etc)
â”œâ”€â”€ sql/             # Scripts SQL (DDL / DML)
â”œâ”€â”€ scripts/         # Scripts Python do pipeline
â”œâ”€â”€ llm_insights/    # AnÃ¡lises e outputs gerados por LLMs
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### âš ï¸ Importante

- Os arquivos dentro de data_src/ devem existir
- Os nomes dos arquivos devem ser exatamente os mesmos referenciados nos scripts Python


### ConfiguraÃ§Ã£o do Banco (DBConnection)
```python
## Informar corretamente as credenciais do banco

def cria_conexao():
    return psycopg2.connect(
        dbname="mydatabase",
        user="admin",
        password="admin",
        host="localhost",
        port="5959"
    )
```

### Executar
```bash
python3 Run-Pipeline.py
```